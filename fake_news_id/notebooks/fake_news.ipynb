{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed8c288",
   "metadata": {},
   "source": [
    "# Classificação de Fake News usando Transformadores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f842d93",
   "metadata": {},
   "source": [
    "## Configuração\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4a96e",
   "metadata": {},
   "source": [
    "### Importando pacotes e dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa614474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando pacotes\n",
    "from typing import List, Any\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023a94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "true_data = pd.read_csv('../datasets/news_dataset/true.csv')\n",
    "true_data['real'] = True\n",
    "true_columns = true_data[['text', 'real']]\n",
    "\n",
    "fake_data = pd.read_csv('../datasets/news_dataset/fake.csv')\n",
    "fake_data['real'] = False\n",
    "fake_columns = fake_data[['text', 'real']]\n",
    "\n",
    "\n",
    "# Creating dataset\n",
    "data = pd.concat([true_columns, fake_columns]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946eecbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real\n",
       "False    23481\n",
       "True     21417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['real'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42adff",
   "metadata": {},
   "source": [
    "### Criando device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f0b44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Usando gpu caso disponível\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76507cd",
   "metadata": {},
   "source": [
    "### Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08a2ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe de dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        tokenizer_name: str,\n",
    "        max_length: int = 512,\n",
    "    ):\n",
    "        super(NewsDataset, self).__init__()\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "        self.tokenizer_name = tokenizer_name\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[index],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b94db",
   "metadata": {},
   "source": [
    "### Funções\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c632c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para tokenizar frase\n",
    "def tokenize_sequence(\n",
    "    tokenizer: PreTrainedTokenizerBase, sequence: List[str], max_length: int\n",
    "):\n",
    "    return tokenizer(\n",
    "        sequence,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c34696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for train and test steps\n",
    "def train_step(\n",
    "    estimator: nn.Module,\n",
    "    loss_fn: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    estimator.to(device)\n",
    "    estimator.train()\n",
    "\n",
    "    for batch in dataloader:\n",
    "        X = batch['input_ids'].to(device)\n",
    "        y = batch['labels'].to(device)\n",
    "\n",
    "        estimator.train()\n",
    "\n",
    "        y_pred = estimator(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y, y_pred.argmax(dim=1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "\n",
    "    print(f'Train loss: {train_loss:.3f} | Train accuracy: {train_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a39f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training loop\n",
    "def test_step(\n",
    "    estimator: nn.Module,\n",
    "    loss_fn: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    estimator.to(device)\n",
    "    estimator.eval()\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for batch in dataloader:\n",
    "            X = batch['input_ids'].to(device)\n",
    "            y = batch['labels'].to(device)\n",
    "\n",
    "            test_pred = estimator(X)\n",
    "\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss /= len(dataloader)\n",
    "\n",
    "        test_acc /= len(dataloader)\n",
    "\n",
    "    print(f'Test loss:  {test_loss:.3f} | Test accuracy:  {test_acc:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7807688",
   "metadata": {},
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82802888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>The following statements were posted to the ve...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16880</th>\n",
       "      <td>Environmental Protection Agency (EPA) enforcer...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12923</th>\n",
       "      <td>Well, what would Friday be without the latest ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>On Tuesday afternoon, legendary journalist Dan...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17117</th>\n",
       "      <td>VALLETTA (Reuters) - The son of Malta s best-k...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text   real\n",
       "3944   The following statements were posted to the ve...   True\n",
       "16880  Environmental Protection Agency (EPA) enforcer...  False\n",
       "12923  Well, what would Friday be without the latest ...  False\n",
       "2525   On Tuesday afternoon, legendary journalist Dan...  False\n",
       "17117  VALLETTA (Reuters) - The son of Malta s best-k...   True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea76dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando valores nulos\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26553710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(414.7604124905341)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando tamanho médio dos textos\n",
    "np.mean([i.count(' ') for _, i in enumerate(data['text'].to_list())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737ce4e",
   "metadata": {},
   "source": [
    "## Criando dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5949ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando dados em treino e teste\n",
    "X = data['text']\n",
    "y = data['real']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Transformando dados para listas\n",
    "X_train, X_test = X_train.tolist(), X_test.tolist()\n",
    "y_train, y_test = y_train.tolist(), y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a7e41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo hiperparâmetros\n",
    "max_length = 200\n",
    "\n",
    "# num_classes = len(bias_id)\n",
    "num_classes = 2\n",
    "\n",
    "tokenizer_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90042150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando datasets\n",
    "train_dataset = NewsDataset(\n",
    "    texts=X_train, labels=y_train, tokenizer_name=tokenizer_name, max_length=max_length\n",
    ")\n",
    "test_dataset = NewsDataset(\n",
    "    texts=X_test, labels=y_test, tokenizer_name=tokenizer_name, max_length=max_length\n",
    ")\n",
    "\n",
    "# Criando dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0cd70",
   "metadata": {},
   "source": [
    "## Criando modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a318a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        num_classes: int,\n",
    "        embed_dim: int,\n",
    "        num_layers: int,\n",
    "        num_heads: int,\n",
    "        max_length: int,\n",
    "        dropout: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, max_length, embed_dim))\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=self.encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(embed_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.emb(x) + self.pos_embed[:, : x.size(1), :]\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.max(dim=1)[0]\n",
    "        out = self.linear(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd55152",
   "metadata": {},
   "source": [
    "## Treinando modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f12cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando modelo\n",
    "model = EncoderClassifier(\n",
    "    vocab_size=train_dataset.tokenizer.vocab_size,\n",
    "    num_classes=num_classes,\n",
    "    embed_dim=128,\n",
    "    num_layers=2,\n",
    "    num_heads=4,\n",
    "    max_length=max_length,\n",
    "    dropout=0.1,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25050b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo perda\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definindo otimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e60415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Setting epochs\n",
    "epochs = 3\n",
    "\n",
    "# Main train loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(\n",
    "        f'Epoch: {epoch}',\n",
    "        '-' * 90,\n",
    "        sep='\\n',\n",
    "        end='\\n',\n",
    "    )\n",
    "\n",
    "    # Train step\n",
    "    train_step(\n",
    "        estimator=model,\n",
    "        dataloader=train_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Test step\n",
    "    test_step(\n",
    "        estimator=model,\n",
    "        loss_fn=loss_fn,\n",
    "        dataloader=test_dataloader,\n",
    "        device=device,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
