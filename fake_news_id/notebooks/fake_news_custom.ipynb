{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed8c288",
   "metadata": {},
   "source": [
    "# Classificação de Fake News usando Transformadores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f842d93",
   "metadata": {},
   "source": [
    "## Configuração\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a5187",
   "metadata": {},
   "source": [
    "### Configurando importação e variável de ambiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa614474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4a96e",
   "metadata": {},
   "source": [
    "### Importando pacotes e dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb73b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando pacotes\n",
    "\n",
    "# Type hinting\n",
    "from typing import List, Any\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from applications.transformer.models.encoder_classifier import EncoderClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023a94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "true_data = pd.read_csv('../datasets/news_dataset/true.csv')\n",
    "true_data['real'] = True\n",
    "true_columns = true_data[['text', 'real']]\n",
    "\n",
    "fake_data = pd.read_csv('../datasets/news_dataset/fake.csv')\n",
    "fake_data['real'] = False\n",
    "fake_columns = fake_data[['text', 'real']]\n",
    "\n",
    "\n",
    "# Creating dataset\n",
    "data = pd.concat([true_columns, fake_columns]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946eecbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real\n",
       "False    23481\n",
       "True     21417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['real'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42adff",
   "metadata": {},
   "source": [
    "### Criando device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f0b44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Usando gpu caso disponível\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76507cd",
   "metadata": {},
   "source": [
    "### Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a2ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe de dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        tokenizer_name: str,\n",
    "        max_length: int = 512,\n",
    "    ):\n",
    "        super(NewsDataset, self).__init__()\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "        self.tokenizer_name = tokenizer_name\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[index],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b94db",
   "metadata": {},
   "source": [
    "### Funções\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c632c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para tokenizar frase\n",
    "def tokenize_sequence(\n",
    "    tokenizer: PreTrainedTokenizerBase, sequence: List[str], max_length: int\n",
    "):\n",
    "    return tokenizer(\n",
    "        sequence,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa7b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c34696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for train and test steps\n",
    "def train_step(\n",
    "    estimator: nn.Module,\n",
    "    loss_fn: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    dataloader: DataLoader,\n",
    "    device: str,\n",
    ") -> None:\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    estimator.to(device)\n",
    "    estimator.train()\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        X = batch['input_ids'].to(device)\n",
    "        y = batch['labels'].to(device)\n",
    "\n",
    "        estimator.train()\n",
    "\n",
    "        y_pred = estimator(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y, y_pred.argmax(dim=1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "\n",
    "    print(f'Train loss: {train_loss:.3f} | Train accuracy: {train_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a39f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training loop\n",
    "def test_step(\n",
    "    estimator: nn.Module,\n",
    "    loss_fn: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: str,\n",
    ") -> None:\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    estimator.to(device)\n",
    "    estimator.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(dataloader):\n",
    "\n",
    "            X = batch['input_ids'].to(device)\n",
    "            y = batch['labels'].to(device)\n",
    "\n",
    "            test_pred = estimator(X)\n",
    "\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss /= len(dataloader)\n",
    "\n",
    "        test_acc /= len(dataloader)\n",
    "\n",
    "    print(f'Test loss:  {test_loss:.3f} | Test accuracy:  {test_acc:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7807688",
   "metadata": {},
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82802888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>March 15 saw yet another Super Tuesday battle ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9398</th>\n",
       "      <td>WASHINGTON (Reuters) - Top U.S. State Departme...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>WASHINGTON (Reuters) - The Senate on Thursday ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13677</th>\n",
       "      <td>HARARE (Reuters) - Robert Mugabe s 37-year rul...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>A veteran has launched a GoFundMe fundraiser t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text   real\n",
       "7478   March 15 saw yet another Super Tuesday battle ...  False\n",
       "9398   WASHINGTON (Reuters) - Top U.S. State Departme...   True\n",
       "270    WASHINGTON (Reuters) - The Senate on Thursday ...   True\n",
       "13677  HARARE (Reuters) - Robert Mugabe s 37-year rul...   True\n",
       "5156   A veteran has launched a GoFundMe fundraiser t...  False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea76dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando valores nulos\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26553710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(414.7604124905341)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando tamanho médio dos textos\n",
    "np.mean([i.count(' ') for _, i in enumerate(data['text'].to_list())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737ce4e",
   "metadata": {},
   "source": [
    "## Criando dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5949ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando dados em treino e teste\n",
    "X = data['text']\n",
    "y = data['real']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Transformando dados para listas\n",
    "X_train, X_test = X_train.tolist(), X_test.tolist()\n",
    "y_train, y_test = y_train.tolist(), y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7e41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo hiperparâmetros\n",
    "max_length = 200\n",
    "\n",
    "# num_classes = len(bias_id)\n",
    "num_classes = 2\n",
    "\n",
    "tokenizer_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90042150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando datasets\n",
    "train_dataset = NewsDataset(\n",
    "    texts=X_train, labels=y_train, tokenizer_name=tokenizer_name, max_length=max_length\n",
    ")\n",
    "test_dataset = NewsDataset(\n",
    "    texts=X_test, labels=y_test, tokenizer_name=tokenizer_name, max_length=max_length\n",
    ")\n",
    "\n",
    "# Criando dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0cd70",
   "metadata": {},
   "source": [
    "## Criando modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd55152",
   "metadata": {},
   "source": [
    "## Treinando modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65f12cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando modelo customizado\n",
    "model = EncoderClassifier(\n",
    "    vocab_size=train_dataset.tokenizer.vocab_size,\n",
    "    n_layers=2,\n",
    "    n_classes=num_classes,\n",
    "    embed_dim=128,\n",
    "    n_heads=4,\n",
    "    ff_hid_dim=4,\n",
    "    max_length=max_length,\n",
    "    pad_idx=train_dataset.tokenizer.pad_token_type_id,\n",
    "    dropout=0.1,\n",
    "    device=device,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25050b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo perda\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definindo otimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1e60415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b971bb1c08b545449f8516ad71c06d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9453c5eec8344410a88cbc5765916dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.086 | Train accuracy: 96.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dfbf08280744aa8f5d708a7d5dabef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.019 | Test accuracy:  99.67%\n",
      "\n",
      "Epoch: 2\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb2056161a340d3bc037b0e9949bbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.034 | Train accuracy: 99.31%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcd9e31ddad446b8e1724e47a147187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.045 | Test accuracy:  98.98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Setting epochs\n",
    "epochs = 2\n",
    "\n",
    "# Main train loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(\n",
    "        f'Epoch: {epoch + 1}',\n",
    "        '-' * 90,\n",
    "        sep='\\n',\n",
    "        end='\\n',\n",
    "    )\n",
    "\n",
    "    # Train step\n",
    "    train_step(\n",
    "        estimator=model,\n",
    "        dataloader=train_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Test step\n",
    "    test_step(\n",
    "        estimator=model,\n",
    "        loss_fn=loss_fn,\n",
    "        dataloader=test_dataloader,\n",
    "        device=device,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
